# âœ‹ Sign-Sight â€” AI Sign Language Coach

> Learn sign language with real-time AI feedback through your webcam.

Sign-Sight is an interactive educational web app that teaches sign language gestures using real-time computer vision. Users practice hand signs and receive instant corrective feedback, transforming sign learning into a gamified, accessible experience.

Built for social impact and inclusive communication.

---

## ğŸŒ Overview

Learning sign language without a teacher is difficult because beginners lack immediate feedback. Sign-Sight solves this by turning your webcam into an AI gesture coach.

The system tracks hand landmarks in real time, evaluates gesture accuracy, and provides actionable feedback like:

- âœ… â€œPerfect!â€
- âš  â€œTilt your thumb inwardâ€
- ğŸ”„ â€œStraighten your fingersâ€

This enables self-guided, confidence-building practice â€” anytime, anywhere.

---

## âœ¨ Core Features

### ğŸ¯ Live Learning Mode
- Guided gesture demonstrations
- Real-time hand tracking
- Instant corrective feedback
- Confidence scoring meter

---

### ğŸ® Practice Mode
- Random sign challenges
- Timed practice rounds
- Accuracy scoring
- Session summary

---

### ğŸ§  Gesture Evaluation Engine
- Hand landmark detection
- Gesture similarity scoring
- Threshold-based accuracy checks
- Instructional feedback generation

---

### ğŸ”Š Voice Interaction
- Text-to-speech coaching feedback
- Optional speech recognition controls

---

### ğŸ† Gamification
- Score tracking
- Combo streaks
- Performance summaries

---

### â™¿ Accessibility Enhancements
- Visual gesture hints
- Slow demonstration mode
- High-contrast UI options

---

## ğŸ§  How It Works

1. Webcam captures live hand movement.
2. Hand landmarks are detected in real time.
3. Landmarks are compared against gesture templates.
4. A similarity score determines accuracy.
5. Feedback is displayed instantly.

Gesture similarity model:

$$
Similarity = 1 - \frac{\sum |L_{user} - L_{template}|}{n}
$$

Where:

- \(L_{user}\) â†’ detected landmarks  
- \(L_{template}\) â†’ reference gesture  
- \(n\) â†’ total comparisons  

This approach enables fast, browser-native gesture evaluation.

---

## ğŸ— Architecture Overview

```
User Webcam
     â†“
Hand Landmark Detection
     â†“
Gesture Comparison Engine
     â†“
Feedback + Scoring System
     â†“
UI Rendering + Voice Feedback
```

Key design principles:

- Client-side gesture processing for low latency
- Modular architecture for scalability
- Responsive UI rendering pipeline

---

## ğŸ›  Tech Stack

### Frontend
- TypeScript
- React + Vite
- Tailwind CSS
- shadcn/ui
- Framer Motion
- React Router
- TanStack React Query

### Computer Vision
- Browser-based hand landmark tracking
- GPU/WebAssembly acceleration

### AI Interaction
- Text-to-speech integration
- Speech recognition (browser-native)

### Backend & Cloud
- Edge Functions runtime
- PostgreSQL database
- Cloud deployment infrastructure

---

## ğŸš€ Installation

### 1. Clone the repository

```bash
git clone https://github.com/your-username/sign-sight.git
cd sign-sight
```

---

### 2. Install dependencies

```bash
npm install
```

---

### 3. Run development server

```bash
npm run dev
```

Open:

```
http://localhost:5173
```

---

## ğŸ” Environment Variables

Create a `.env` file if required:

```env
TTS_API_KEY=your_key_here
```

---

## â–¶ Demo

Live demo:

ğŸ‘‰ https://your-demo-link.com

Video walkthrough:

ğŸ‘‰ https://your-video-link.com

---

## ğŸ“¦ Project Structure

```
src/
 â”œâ”€â”€ components/
 â”œâ”€â”€ vision/
 â”œâ”€â”€ feedback/
 â”œâ”€â”€ hooks/
 â”œâ”€â”€ pages/
 â””â”€â”€ utils/
```

- `vision/` â†’ gesture tracking logic  
- `feedback/` â†’ evaluation engine  
- `components/` â†’ UI modules  

---

## ğŸ§ª Performance Goals

- Smooth real-time tracking (~30 FPS)
- Low-latency feedback
- Browser-optimized rendering

---

## ğŸŒ± Future Roadmap

- Full sign alphabet training
- Word and phrase recognition
- Personalized learning profiles
- AI classifier training
- Multiplayer practice modes
- Mobile optimization

---

## ğŸ¯ Impact

Sign-Sight promotes:

- Inclusive communication
- Accessibility learning
- Confidence-building education

The goal is to make sign language learning approachable, interactive, and widely accessible.

---

## ğŸ¤ Contributing

Contributions are welcome!

1. Fork the project
2. Create a feature branch
3. Submit a pull request

---

## ğŸ“„ License

MIT License â€” free to use and modify.

---

## ğŸ’¡ Acknowledgments

Inspired by inclusive education, accessibility advocacy, and the power of real-time AI learning tools.

---

## â­ Support

If you like this project:

ğŸ‘‰ Star the repo  
ğŸ‘‰ Share it  
ğŸ‘‰ Contribute  

Together we make communication more inclusive.
